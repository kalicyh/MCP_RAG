# Instrucciones para Agentes de IA - Sistema RAG Mejorado

## üéØ Prop√≥sito del Sistema

Este sistema RAG (Retrieval-Augmented Generation) **mejorado** permite a los agentes de IA:
- **Almacenar informaci√≥n** de forma persistente con procesamiento inteligente
- **Consultar conocimiento** previamente guardado con metadatos estructurales
- **Rastrear fuentes** de informaci√≥n con detalles completos
- **Procesar documentos** autom√°ticamente con m√°s de 25 formatos
- **Preservar estructura** sem√°ntica de documentos (t√≠tulos, tablas, listas)
- **Eliminar ruido** autom√°ticamente (cabeceras, pies de p√°gina, contenido irrelevante)
- **üîç Realizar b√∫squedas filtradas** por metadatos para mayor precisi√≥n
- **üìä Obtener estad√≠sticas** detalladas de la base de conocimientos

## üöÄ Nuevas Caracter√≠sticas del Sistema Mejorado

### **üß† Procesamiento Inteligente con Unstructured**
- **Preservaci√≥n de Estructura**: Mantiene t√≠tulos, listas, tablas organizadas
- **Limpieza Autom√°tica**: Elimina cabeceras, pies de p√°gina y contenido irrelevante
- **Metadatos Estructurales**: Informaci√≥n detallada sobre la estructura del documento
- **Sistema de Fallbacks**: M√∫ltiples estrategias garantizan procesamiento exitoso

### **üìã Soporte Expandido de Formatos**
**M√°s de 25 formatos soportados:**
- **Documentos de Office**: PDF, DOCX, PPTX, XLSX, RTF
- **OpenDocument**: ODT, ODP, ODS
- **Web y Markup**: HTML, XML, Markdown
- **Texto y Datos**: TXT, CSV, TSV, JSON, YAML
- **Im√°genes con OCR**: PNG, JPG, TIFF, BMP
- **Correos Electr√≥nicos**: EML, MSG

### **üéØ Chunking Sem√°ntico Inteligente**
- **Divisi√≥n Natural**: Respeta la estructura del documento
- **Overlap Inteligente**: Mantiene continuidad entre fragmentos
- **Contexto Preservado**: No corta en medio de ideas

### **üîç B√∫squedas Avanzadas con Filtros**
- **Filtrado por Tipo de Archivo**: Buscar solo en PDFs, DOCX, etc.
- **Filtrado por Estructura**: Documentos con tablas, t√≠tulos espec√≠ficos
- **Filtrado por M√©todo de Procesamiento**: Unstructured vs MarkItDown
- **Filtros Combinados**: M√∫ltiples criterios simult√°neos

### **üìà Estad√≠sticas de Base de Conocimientos**
- **An√°lisis de Contenido**: Distribuci√≥n por tipo de archivo
- **M√©tricas Estructurales**: Total de tablas, t√≠tulos, listas
- **Informaci√≥n de Procesamiento**: M√©todos utilizados
- **Insights Autom√°ticos**: Promedios y tendencias

## üõ†Ô∏è Herramientas Disponibles

### 1. `learn_text(text, source_name)`
**Cu√°ndo usar**: Para a√±adir informaci√≥n textual que el agente debe recordar.

**Ejemplos de uso**:
```python
# A√±adir definiciones importantes
learn_text("La inteligencia artificial es la simulaci√≥n de procesos de inteligencia humana por m√°quinas.", "ai_definitions")

# Guardar notas de conversaci√≥n
learn_text("El usuario mencion√≥ que trabaja en el sector financiero y necesita an√°lisis de datos.", "conversation_notes")

# Almacenar hechos espec√≠ficos
learn_text("La temperatura de fusi√≥n del titanio es 1,668¬∞C.", "material_properties")
```

### 2. `learn_document(file_path)` - **MEJORADO**
**Cu√°ndo usar**: Para procesar y almacenar contenido de archivos con procesamiento inteligente.

**Nuevas capacidades**:
- **Procesamiento Inteligente**: Usa Unstructured para preservar estructura
- **Metadatos Estructurales**: Informaci√≥n sobre t√≠tulos, tablas, listas
- **Sistema de Fallbacks**: M√∫ltiples estrategias de procesamiento
- **Soporte Amplio**: M√°s de 25 formatos de archivo

**Ejemplos de uso**:
```python
# Procesar un informe con estructura compleja
learn_document("C:/Documents/informe_trimestral.pdf")

# A√±adir un manual t√©cnico con tablas y listas
learn_document("D:/Manuals/manual_usuario.docx")

# Importar datos de una hoja de c√°lculo
learn_document("E:/Data/datos_ventas.xlsx")

# Procesar im√°genes con texto (requiere OCR)
learn_document("F:/Scans/documento_escaneado.png")

# Procesar correos electr√≥nicos
learn_document("G:/Emails/importante.msg")
```

**Respuesta mejorada de `learn_document`**:
```
‚úÖ **Documento procesado exitosamente**
üìÑ **Archivo:** informe_trimestral.pdf
üìã **Tipo:** PDF
üîß **M√©todo:** Unstructured Enhanced

üìä **Estructura del documento:**
   ‚Ä¢ Elementos totales: 15
   ‚Ä¢ T√≠tulos: 3
   ‚Ä¢ Tablas: 2
   ‚Ä¢ Listas: 4
   ‚Ä¢ Bloques narrativos: 6

üíæ **Copia guardada:** ./converted_docs/informe_trimestral_unstructured_enhanced.md
üìö **Estado:** A√±adido a la base de conocimientos con chunking sem√°ntico
```

### 3. `learn_from_url(url)` - **MEJORADO**
**Cu√°ndo usar**: Para procesar contenido web o descargar y procesar archivos directamente desde URLs.

**Nuevas capacidades**:
- **Detecci√≥n Autom√°tica**: Identifica archivos descargables vs p√°ginas web
- **Procesamiento Mejorado**: Usa Unstructured para archivos descargados
- **MarkItDown para Web**: Mantiene procesamiento web tradicional
- **Metadatos Enriquecidos**: Informaci√≥n del dominio y m√©todo de procesamiento

**Ejemplos de uso**:
```python
# Descargar y procesar un PDF desde una URL
learn_from_url("https://example.com/informe.pdf")

# Procesar una p√°gina web
learn_from_url("https://example.com/articulo")

# Descargar y procesar un documento de Word
learn_from_url("https://example.com/manual.docx")
```

### 4. `ask_rag(query)` - **MEJORADO**
**Cu√°ndo usar**: Para consultar informaci√≥n previamente almacenada con informaci√≥n detallada de fuentes.

**Nuevas capacidades**:
- **Metadatos Estructurales**: Informaci√≥n sobre estructura de documentos
- **Informaci√≥n de Chunks**: N√∫mero de fragmento y total
- **M√©todo de Procesamiento**: Tipo de procesamiento usado
- **Informaci√≥n de Confianza**: Nivel de confianza basado en n√∫mero de fuentes
- **Detecci√≥n de Alucinaciones**: Previene respuestas falsas cuando no hay informaci√≥n
- **Sugerencias √ötiles**: Gu√≠a cuando no hay informaci√≥n disponible

**Ejemplos de uso**:
```python
# Buscar informaci√≥n espec√≠fica
ask_rag("¬øCu√°l es la temperatura de fusi√≥n del titanio?")

# Consultar sobre un documento procesado
ask_rag("¬øQu√© dice el informe trimestral sobre las ventas?")

# Buscar contexto sobre un tema
ask_rag("¬øQu√© informaci√≥n tenemos sobre inteligencia artificial?")
```

**Respuesta mejorada de `ask_rag`**:
```
ü§ñ **Respuesta:**
El punto de fusi√≥n del titanio es 1,668 ¬∞C. Esta propiedad lo hace ideal para aplicaciones aeroespaciales donde se requieren materiales resistentes a altas temperaturas.

üìö **Fuentes de informaci√≥n utilizadas:**

   1. **material_properties**
      - **Tipo:** MANUAL_INPUT
      - **Procesamiento:** Manual Text
      - **Procesado:** 21/06/2025 17:30
      - **Fragmento:** 1 de 1
      - **Fragmento Relevante:**
        > _La temperatura de fusi√≥n del titanio es 1,668¬∞C._

   2. **datasheet_titanium.pdf**
      - **Ruta:** `D:\Docs\datasheet_titanium.pdf`
      - **Tipo:** PDF
      - **Procesamiento:** Unstructured Enhanced
      - **Estructura:** 12 elementos (2 t√≠tulos, 1 tabla, 3 listas)
      - **Fragmento:** 3 de 5
      - **Procesado:** 21/06/2025 17:32
      - **Fragmento Relevante:**
        > _...el titanio puro tiene un punto de fusi√≥n de 1,668 grados Celsius, lo que lo hace ideal para aplicaciones aeroespaciales..._

‚úÖ **Alta confianza:** Respuesta basada en m√∫ltiples fuentes
üß† **Procesamiento inteligente:** 1 fuentes procesadas con Unstructured (preservaci√≥n de estructura)
```

**Manejo de errores mejorado**:
```
ü§ñ **Respuesta:**

‚ùå **No se encontr√≥ informaci√≥n relevante en la base de conocimientos para responder tu pregunta.**

üí° **Sugerencias:**
‚Ä¢ Verifica que hayas cargado documentos relacionados con tu pregunta
‚Ä¢ Intenta reformular tu pregunta con t√©rminos m√°s espec√≠ficos
‚Ä¢ Usa `get_knowledge_base_stats()` para ver qu√© informaci√≥n est√° disponible
‚Ä¢ Considera cargar m√°s documentos sobre el tema que te interesa

‚ö†Ô∏è **Nota:** El sistema solo puede responder bas√°ndose en la informaci√≥n que ha sido previamente cargada en la base de conocimientos.
```

### 5. `ask_rag_filtered(query, file_type, min_tables, min_titles, processing_method)` - **NUEVA**
**Cu√°ndo usar**: Para realizar b√∫squedas m√°s precisas y espec√≠ficas usando filtros de metadatos.

**Capacidades de filtrado**:
- **`file_type`**: Filtrar por tipo de archivo (ej. ".pdf", ".docx", ".xlsx")
- **`min_tables`**: Solo documentos con m√≠nimo n√∫mero de tablas
- **`min_titles`**: Solo documentos con m√≠nimo n√∫mero de t√≠tulos
- **`processing_method`**: Filtrar por m√©todo de procesamiento usado

**Ejemplos de uso**:
```python
# Buscar solo en documentos PDF
ask_rag_filtered("¬øQu√© informaci√≥n tenemos sobre ventas?", file_type=".pdf")

# Buscar documentos con tablas de datos
ask_rag_filtered("¬øQu√© datos tabulares tenemos?", min_tables=1)

# Buscar en documentos procesados con Unstructured
ask_rag_filtered("¬øQu√© contenido tenemos?", processing_method="unstructured_enhanced")

# Combinar m√∫ltiples filtros
ask_rag_filtered("¬øQu√© reportes PDF con tablas tenemos?", file_type=".pdf", min_tables=1)
```

**Respuesta de `ask_rag_filtered`**:
```
ü§ñ **Respuesta filtrada:**
Se encontraron 3 documentos PDF con tablas que contienen informaci√≥n sobre ventas.

üìö **Fuentes filtradas utilizadas:**
   1. **reporte_ventas_q1.pdf** (PDF, 2 tablas)
   2. **datos_ventas_2024.pdf** (PDF, 1 tabla)
   3. **analisis_ventas.pdf** (PDF, 3 tablas)

‚úÖ **Filtros aplicados:** Tipo de archivo: PDF, M√≠nimo tablas: 1
üìä **Resultados:** 3 de 15 documentos totales
```

### 6. `get_knowledge_base_stats()` - **NUEVA**
**Cu√°ndo usar**: Para obtener informaci√≥n detallada sobre el contenido almacenado en la base de conocimientos.

**Informaci√≥n proporcionada**:
- **Total de documentos** almacenados
- **Distribuci√≥n por tipo de archivo** (PDF, DOCX, etc.)
- **Estad√≠sticas estructurales** (total de tablas, t√≠tulos, listas)
- **M√©todos de procesamiento** utilizados
- **Promedios** por documento

**Ejemplos de uso**:
```python
# Obtener estad√≠sticas generales
get_knowledge_base_stats()

# Usar antes de b√∫squedas filtradas para entender el contenido
stats = get_knowledge_base_stats()
# Luego usar ask_rag_filtered con filtros apropiados
```

**Respuesta de `get_knowledge_base_stats`**:
```
üìä **Estad√≠sticas de la Base de Conocimientos**

üìÑ **Documentos totales:** 25
üìã **Distribuci√≥n por tipo:**
   ‚Ä¢ PDF: 12 documentos (48%)
   ‚Ä¢ DOCX: 8 documentos (32%)
   ‚Ä¢ XLSX: 3 documentos (12%)
   ‚Ä¢ TXT: 2 documentos (8%)

üèóÔ∏è **Estructura del contenido:**
   ‚Ä¢ Total de tablas: 47
   ‚Ä¢ Total de t√≠tulos: 156
   ‚Ä¢ Total de listas: 89
   ‚Ä¢ Promedio tablas por documento: 1.9
   ‚Ä¢ Promedio t√≠tulos por documento: 6.2

üîß **M√©todos de procesamiento:**
   ‚Ä¢ Unstructured Enhanced: 20 documentos (80%)
   ‚Ä¢ MarkItDown: 3 documentos (12%)
   ‚Ä¢ LangChain Fallback: 2 documentos (8%)

üìà **Insights:**
   ‚Ä¢ 76% de documentos contienen tablas
   ‚Ä¢ 92% procesados con m√©todo avanzado
   ‚Ä¢ Contenido rico en estructura sem√°ntica
```

### 7. `get_embedding_cache_stats()` - **NUEVA**
**Cu√°ndo usar**: Para monitorear el rendimiento del cache de embeddings y optimizar el sistema.

**Informaci√≥n proporcionada**:
- **Total de requests** al cache
- **Hits en memoria** (muy r√°pidos)
- **Hits en disco** (r√°pidos, persistentes)
- **Misses** (requieren c√°lculo nuevo)
- **Tasas de √©xito** (porcentajes)
- **Tama√±o del cache** en memoria
- **Ubicaci√≥n** del cache en disco

**Ejemplos de uso**:
```python
# Verificar rendimiento del cache
get_embedding_cache_stats()

# Monitorear antes y despu√©s de procesar documentos
stats_before = get_embedding_cache_stats()
learn_document("documento.pdf")
stats_after = get_embedding_cache_stats()
```

**Respuesta de `get_embedding_cache_stats`**:
```
üìä **Estad√≠sticas del Cache de Embeddings**

üîÑ **Total de requests:** 150
‚ö° **Memory hits:** 45 (30.0%)
üíæ **Disk hits:** 85 (56.7%)
‚ùå **Misses:** 20 (13.3%)
üìà **Overall hit rate:** 86.7%

üíæ **Cache en memoria:** 45 embeddings
üìÅ **Cache en disco:** 130 embeddings
üìÇ **Ubicaci√≥n:** ./embedding_cache/

üöÄ **Rendimiento:** Cache funcionando de manera √≥ptima
```

### 8. `clear_embedding_cache_tool()` - **NUEVA**
**Cu√°ndo usar**: Para limpiar el cache de embeddings cuando sea necesario.

**Opciones de limpieza**:
- **Limpieza completa**: Elimina cache en memoria y disco
- **Liberaci√≥n de recursos**: √ötil cuando hay problemas de memoria
- **Reinicio limpio**: Para empezar desde cero

**Ejemplos de uso**:
```python
# Limpiar cache cuando hay problemas
clear_embedding_cache_tool()

# Limpiar antes de procesar muchos documentos nuevos
clear_embedding_cache_tool()
learn_document("documento1.pdf")
learn_document("documento2.pdf")
```

**Respuesta de `clear_embedding_cache_tool`**:
```
üßπ **Cache de Embeddings Limpiado**

‚úÖ **Acciones realizadas:**
   ‚Ä¢ Cache en memoria limpiado
   ‚Ä¢ Cache en disco limpiado
   ‚Ä¢ Estad√≠sticas reiniciadas

üìä **Estado actual:**
   ‚Ä¢ Memory hits: 0
   ‚Ä¢ Disk hits: 0
   ‚Ä¢ Misses: 0
   ‚Ä¢ Total requests: 0

üí° **Nota:** El cache se reconstruir√° autom√°ticamente con el uso
```

### 9. `optimize_vector_database()` - **NUEVA**
**Cu√°ndo usar**: Para optimizar la base de datos vectorial y mejorar el rendimiento de b√∫squedas.

**Informaci√≥n proporcionada**:
- **Optimizaci√≥n de √≠ndices**: Reorganiza los √≠ndices internos
- **Estad√≠sticas antes/despu√©s**: Comparaci√≥n de rendimiento
- **Documentos procesados**: N√∫mero de documentos optimizados
- **Beneficios**: B√∫squedas m√°s r√°pidas y precisas

**Ejemplos de uso**:
```python
# Optimizar cuando las b√∫squedas son lentas
optimize_vector_database()

# Optimizar despu√©s de a√±adir muchos documentos
learn_document("documento1.pdf")
learn_document("documento2.pdf")
optimize_vector_database()
```

**Respuesta de `optimize_vector_database`**:
```
‚úÖ **Base de datos vectorial optimizada exitosamente**

üìä **Estad√≠sticas antes de la optimizaci√≥n:**
   ‚Ä¢ Documentos totales: 8,934

üìä **Estad√≠sticas despu√©s de la optimizaci√≥n:**
   ‚Ä¢ Documentos totales: 8,934

üöÄ **Beneficios:**
   ‚Ä¢ B√∫squedas m√°s r√°pidas
   ‚Ä¢ Mejor precisi√≥n en resultados
   ‚Ä¢ √çndices optimizados
```

### 10. `get_vector_database_stats()` - **NUEVA**
**Cu√°ndo usar**: Para obtener estad√≠sticas detalladas de la base de datos vectorial.

**Informaci√≥n proporcionada**:
- **Total de documentos** almacenados
- **Distribuci√≥n por tipo de archivo** (PDF, DOCX, etc.)
- **M√©todos de procesamiento** utilizados
- **Perfil recomendado** basado en el tama√±o
- **Dimensi√≥n de embeddings**

**Ejemplos de uso**:
```python
# Verificar el estado de la base de datos
get_vector_database_stats()

# Analizar distribuci√≥n de documentos
stats = get_vector_database_stats()
# Luego usar ask_rag_filtered con filtros apropiados
```

**Respuesta de `get_vector_database_stats`**:
```
üìä **Estad√≠sticas de la Base de Datos Vectorial**

üìö **Informaci√≥n General:**
   ‚Ä¢ Total de documentos: 8,934
   ‚Ä¢ Nombre de colecci√≥n: mcp_rag_collection
   ‚Ä¢ Dimensi√≥n de embeddings: 768

üìÑ **Distribuci√≥n por tipo de archivo:**
   ‚Ä¢ .pdf: 5,093 documentos
   ‚Ä¢ .xlsx: 2,642 documentos
   ‚Ä¢ .docx: 396 documentos
   ‚Ä¢ .txt: 502 documentos

üîß **M√©todos de procesamiento:**
   ‚Ä¢ unstructured_enhanced: 8,500 documentos
   ‚Ä¢ markitdown: 434 documentos

üéØ **Perfil recomendado:** medium
```

### 11. `reindex_vector_database(profile)` - **NUEVA**
**Cu√°ndo usar**: Para reindexar la base de datos con una configuraci√≥n optimizada.

**Par√°metros**:
- **`profile`**: Perfil de configuraci√≥n ('small', 'medium', 'large', 'auto')

**Ejemplos de uso**:
```python
# Reindexar con perfil autom√°tico
reindex_vector_database('auto')

# Reindexar con perfil espec√≠fico para bases grandes
reindex_vector_database('large')

# Reindexar cuando hay problemas de rendimiento
reindex_vector_database('medium')
```

**Respuesta de `reindex_vector_database`**:
```
‚úÖ **Base de datos vectorial reindexada exitosamente**

üìä **Informaci√≥n del proceso:**
   ‚Ä¢ Perfil aplicado: medium
   ‚Ä¢ Documentos procesados: 8,934

üöÄ **Beneficios del reindexado:**
   ‚Ä¢ √çndices optimizados para el tama√±o actual
   ‚Ä¢ B√∫squedas m√°s r√°pidas y precisas
   ‚Ä¢ Mejor uso de memoria
```

## üîÑ Flujo de Trabajo Recomendado

### Paso 1: Cargar Informaci√≥n
```python
# Opci√≥n A: Texto directo
learn_text("Informaci√≥n importante...", "mi_fuente")

# Opci√≥n B: Documento con procesamiento mejorado
learn_document("ruta/al/documento.pdf")

# Opci√≥n C: Contenido web o archivo desde URL
learn_from_url("https://example.com/documento.pdf")
```

### Paso 2: Explorar el Contenido
```python
# Obtener estad√≠sticas para entender qu√© tenemos
get_knowledge_base_stats()
```

### Paso 3: Consultar Informaci√≥n
```python
# B√∫squeda general
respuesta = ask_rag("¬øCu√°l es la informaci√≥n importante?")

# B√∫squeda filtrada para mayor precisi√≥n
respuesta_filtrada = ask_rag_filtered("¬øQu√© datos tenemos?", file_type=".pdf", min_tables=1)
```

### Paso 4: Verificar Fuentes Mejoradas
- Las respuestas incluyen metadatos estructurales detallados
- Informaci√≥n sobre m√©todo de procesamiento
- Nivel de confianza de la respuesta
- Filtros aplicados (en b√∫squedas filtradas)

## üìä Ejemplo de Respuesta Mejorada de `ask_rag`

```
ü§ñ **Respuesta:**
El punto de fusi√≥n del titanio es 1,668 ¬∞C. Esta propiedad lo hace ideal para aplicaciones aeroespaciales donde se requieren materiales resistentes a altas temperaturas.

üìö **Fuentes de informaci√≥n utilizadas:**

   1. **material_properties**
      - **Tipo:** MANUAL_INPUT
      - **Procesamiento:** Manual Text
      - **Procesado:** 21/06/2025 17:30
      - **Fragmento:** 1 de 1
      - **Fragmento Relevante:**
        > _La temperatura de fusi√≥n del titanio es 1,668¬∞C._

   2. **datasheet_titanium.pdf**
      - **Ruta:** `D:\Docs\datasheet_titanium.pdf`
      - **Tipo:** PDF
      - **Procesamiento:** Unstructured Enhanced
      - **Estructura:** 12 elementos (2 t√≠tulos, 1 tabla, 3 listas)
      - **Fragmento:** 3 de 5
      - **Procesado:** 21/06/2025 17:32
      - **Fragmento Relevante:**
        > _...el titanio puro tiene un punto de fusi√≥n de 1,668 grados Celsius, lo que lo hace ideal para aplicaciones aeroespaciales..._

‚úÖ **Alta confianza:** Respuesta basada en m√∫ltiples fuentes
üß† **Procesamiento inteligente:** 1 fuentes procesadas con Unstructured (preservaci√≥n de estructura)
```

## ‚ö†Ô∏è Consideraciones Importantes

### Limitaciones
- **Alcance**: Solo puede acceder a informaci√≥n previamente almacenada
- **OCR**: Para im√°genes con texto, requiere Tesseract OCR instalado
- **Tama√±o**: Los archivos muy grandes pueden tardar en procesarse
- **Formato**: Algunos formatos muy espec√≠ficos pueden requerir dependencias adicionales
- **Filtros**: Los filtros muy restrictivos pueden no devolver resultados

### Mejores Pr√°cticas
1. **Usar nombres descriptivos** para las fuentes
2. **Verificar las rutas** de archivos antes de procesarlos
3. **Revisar las fuentes** en las respuestas para validar informaci√≥n
4. **Procesar documentos** antes de hacer preguntas sobre ellos
5. **Aprovechar metadatos estructurales** para entender mejor el contenido
6. **Usar chunking sem√°ntico** para documentos con estructura compleja
7. **Explorar estad√≠sticas** antes de hacer b√∫squedas filtradas
8. **Combinar filtros** para b√∫squedas m√°s precisas
9. **Verificar resultados** de b√∫squedas filtradas para confirmar relevancia
10. **Monitorear el cache** usando `get_embedding_cache_stats()` para optimizar rendimiento
11. **Limpiar cache** cuando sea necesario usando `clear_embedding_cache_tool()`
12. **Aprovechar la persistencia** del cache en disco entre sesiones
13. **Optimizar la base vectorial** usando `optimize_vector_database()` cuando las b√∫squedas sean lentas
14. **Monitorear estad√≠sticas** de la base vectorial con `get_vector_database_stats()`
15. **Reindexar cuando sea necesario** usando `reindex_vector_database()` para mejorar rendimiento

### Manejo de Errores Mejorado
- **Archivo no encontrado**: Verificar la ruta del archivo
- **Formato no soportado**: El sistema soporta m√°s de 25 formatos
- **Error de OCR**: Instalar Tesseract para procesar im√°genes con texto
- **Error de Unstructured**: Verificar instalaci√≥n: `pip install 'unstructured[local-inference,all-docs]'`
- **Sin informaci√≥n**: Asegurarse de que se haya cargado informaci√≥n relevante
- **Filtros sin resultados**: Usar filtros menos restrictivos o verificar estad√≠sticas
- **Error en filtros**: Verificar formato de par√°metros de filtrado
- **Cache corrupto**: Usar `clear_embedding_cache_tool()` para limpiar
- **Baja tasa de aciertos**: Revisar patrones de consulta y optimizar

## üìù Ejemplos de Casos de Uso Mejorados

### Caso 1: Investigaci√≥n Acad√©mica con Documentos Complejos
```python
# 1. Cargar papers de investigaci√≥n con estructura compleja
learn_document("paper_ai_ethics.pdf")  # Preserva t√≠tulos, tablas, referencias
learn_document("survey_machine_learning.docx")  # Mantiene formato y estructura

# 2. Explorar el contenido cargado
get_knowledge_base_stats()

# 3. Consultar informaci√≥n espec√≠fica con filtros
ask_rag_filtered("¬øCu√°les son los principales desaf√≠os √©ticos de la IA?", file_type=".pdf", min_titles=3)
```

### Caso 2: An√°lisis de Datos con Hojas de C√°lculo
```python
# 1. Cargar datos y reportes con formato preservado
learn_document("datos_ventas.xlsx")  # Procesa tablas y datos estructurados
learn_document("reporte_analisis.pdf")  # Mantiene gr√°ficos y tablas

# 2. Buscar espec√≠ficamente datos tabulares
ask_rag_filtered("¬øCu√°les fueron las ventas del Q3?", min_tables=1)

# 3. Verificar qu√© tipos de datos tenemos
get_knowledge_base_stats()
```

### Caso 3: Asistente Personal con Documentos Escaneados
```python
# 1. Almacenar informaci√≥n personal y documentos escaneados
learn_text("Mi direcci√≥n es 123 Calle Principal", "personal_info")
learn_document("documento_identidad_escaneado.png")  # OCR autom√°tico

# 2. Consultar cuando sea necesario
ask_rag("¬øCu√°l es mi informaci√≥n de contacto?")

# 3. Verificar documentos procesados con OCR
ask_rag_filtered("¬øQu√© documentos escaneados tenemos?", processing_method="unstructured_enhanced")
```

### Caso 4: Investigaci√≥n Web con Descarga de Archivos
```python
# 1. Procesar contenido web y descargar documentos
learn_from_url("https://example.com/articulo")  # P√°gina web
learn_from_url("https://example.com/informe.pdf")  # Descarga y procesa PDF

# 2. Explorar contenido web vs documentos
get_knowledge_base_stats()

# 3. Consultar informaci√≥n combinada con filtros
ask_rag_filtered("¬øQu√© informaci√≥n tenemos sobre el tema?", file_type=".pdf")
ask_rag_filtered("¬øQu√© contenido web tenemos?", processing_method="markitdown")
```

### Caso 5: Gesti√≥n de Documentos Empresariales
```python
# 1. Cargar diferentes tipos de documentos empresariales
learn_document("manual_empleados.docx")
learn_document("reporte_financiero.pdf")
learn_document("datos_ventas.xlsx")

# 2. Obtener estad√≠sticas del contenido
get_knowledge_base_stats()

# 3. B√∫squedas espec√≠ficas por tipo de contenido
# Solo manuales y gu√≠as
ask_rag_filtered("¬øQu√© procedimientos tenemos?", file_type=".docx")

# Solo reportes con datos
ask_rag_filtered("¬øQu√© datos financieros tenemos?", min_tables=1)

# Solo documentos procesados con m√©todo avanzado
ask_rag_filtered("¬øQu√© contenido de alta calidad tenemos?", processing_method="unstructured_enhanced")
```

## üéØ Consejos para Agentes Mejorados

1. **Aprovecha la estructura**: Los documentos mantienen t√≠tulos, tablas y listas
2. **Usa metadatos estructurales**: Para entender mejor el contenido de las fuentes
3. **Verifica el m√©todo de procesamiento**: Unstructured vs MarkItDown
4. **Conf√≠a en el chunking sem√°ntico**: Mejor contexto en las respuestas
5. **Revisa la confianza**: Respuestas con m√∫ltiples fuentes son m√°s confiables
6. **Usa formatos soportados**: M√°s de 25 formatos disponibles
7. **Maneja errores espec√≠ficos**: Cada tipo de error tiene consejos √∫tiles
8. **Aprovecha OCR**: Para procesar im√°genes con texto
9. **Usa URLs inteligentemente**: El sistema detecta autom√°ticamente archivos vs p√°ginas web
10. **Valida con fuentes**: Siempre revisa la informaci√≥n de fuentes en las respuestas
11. **Explora estad√≠sticas**: Usa `get_knowledge_base_stats()` para entender el contenido
12. **Aplica filtros estrat√©gicamente**: Para b√∫squedas m√°s precisas y relevantes
13. **Combina filtros**: Usa m√∫ltiples criterios para b√∫squedas muy espec√≠ficas
14. **Verifica resultados de filtros**: Confirma que los filtros devuelven informaci√≥n relevante
15. **Optimiza consultas**: Usa filtros para reducir ruido en las respuestas

## üîß Informaci√≥n T√©cnica para Agentes

### **Procesamiento de Documentos**
- **Unstructured Enhanced**: Para la mayor√≠a de formatos con preservaci√≥n de estructura
- **MarkItDown**: Para p√°ginas web y contenido HTML
- **Fallbacks**: M√∫ltiples estrategias garantizan procesamiento exitoso

### **Metadatos Estructurales**
- **total_elements**: N√∫mero total de elementos en el documento
- **titles_count**: N√∫mero de t√≠tulos identificados
- **tables_count**: N√∫mero de tablas extra√≠das
- **lists_count**: N√∫mero de listas identificadas
- **narrative_blocks**: Bloques de texto narrativo

### **Sistema de Filtrado**
- **Filtros de tipo de archivo**: `.pdf`, `.docx`, `.xlsx`, etc.
- **Filtros estructurales**: `min_tables`, `min_titles`
- **Filtros de procesamiento**: `unstructured_enhanced`, `markitdown`
- **Filtros combinados**: M√∫ltiples criterios simult√°neos

### **Niveles de Confianza**
- **Alta confianza**: Respuesta basada en 3+ fuentes
- **Confianza media**: Respuesta basada en 2 fuentes
- **Confianza limitada**: Respuesta basada en 1 fuente

### **M√©todos de Procesamiento**
- **unstructured_enhanced**: Procesamiento inteligente con preservaci√≥n de estructura
- **markitdown**: Procesamiento web tradicional
- **langchain_fallback**: Cargadores espec√≠ficos de LangChain

### **Estad√≠sticas de Base de Conocimientos**
- **Distribuci√≥n por tipo**: Porcentaje de cada formato de archivo
- **M√©tricas estructurales**: Totales y promedios de elementos
- **M√©todos de procesamiento**: Distribuci√≥n de estrategias utilizadas
- **Insights autom√°ticos**: An√°lisis de calidad del contenido 

## Herramientas Disponibles

### üîç **B√∫squeda y Consulta**
- `search_documents`: Busca documentos en la base de conocimiento
- `ask_rag`: Realiza consultas RAG con el modelo de lenguaje
- `ask_rag_filtered`: Consultas RAG con filtros de metadatos

### üìä **Gesti√≥n de Base de Datos**
- `get_document_statistics`: Obtiene estad√≠sticas detalladas de la base
- `get_vector_store_stats`: Estad√≠sticas b√°sicas de la base vectorial
- `get_vector_store_stats_advanced`: **NUEVO** - Estad√≠sticas avanzadas con informaci√≥n de escalabilidad

### ‚ö° **Optimizaci√≥n y Rendimiento**
- `optimize_vector_store`: Optimiza la base vectorial (detecta autom√°ticamente si es base grande)
- `reindex_vector_store`: Reindexa la base con nuevo perfil
- `optimize_vector_store_large`: **NUEVO** - Optimizaci√≥n incremental para bases muy grandes
- `reindex_vector_store_large`: **NUEVO** - Reindexado incremental para bases muy grandes

### üß† **Cache de Embeddings**
- `get_cache_stats`: Estad√≠sticas del cache de embeddings
- `print_cache_stats`: Imprime estad√≠sticas del cache
- `clear_embedding_cache`: Limpia el cache de embeddings

### üîß **Configuraci√≥n y Perfiles**
- `get_optimal_vector_store_profile`: Detecta el perfil √≥ptimo autom√°ticamente
- `get_vector_store`: Obtiene la base vectorial con perfil optimizado

## Caracter√≠sticas de Escalabilidad

### **Detecci√≥n Autom√°tica de Tama√±o**
El sistema detecta autom√°ticamente si la base de datos es "grande" (>10,000 documentos) y aplica optimizaciones especiales:

- **Bases peque√±as/medianas** (<10,000 docs): Optimizaci√≥n est√°ndar
- **Bases grandes** (>10,000 docs): Optimizaci√≥n incremental con checkpoints

### **Optimizaci√≥n Incremental para Bases Grandes**
- **Procesamiento por lotes**: Batches de 2,000 documentos
- **Checkpoints autom√°ticos**: Cada 5,000 documentos
- **Monitoreo de memoria**: Control de uso de RAM
- **Recuperaci√≥n autom√°tica**: Reanudaci√≥n desde checkpoint en caso de error
- **Almacenamiento temporal**: Datos guardados en disco durante proceso

### **Estimaciones de Rendimiento**
El sistema proporciona estimaciones basadas en el tama√±o:
- **<1,000 docs**: 1-5 minutos
- **1,000-10,000 docs**: 5-15 minutos  
- **10,000-50,000 docs**: 15-45 minutos
- **50,000-100,000 docs**: 45-90 minutos
- **>100,000 docs**: 2-4 horas

## Mejores Pr√°cticas

### **Para Bases Peque√±as/Medianas**
1. Usar optimizaci√≥n est√°ndar
2. Cache de embeddings mejora rendimiento
3. Reindexado ocasional para mantenimiento

### **Para Bases Grandes**
1. Optimizaci√≥n incremental autom√°tica
2. Monitorear uso de memoria
3. Checkpoints frecuentes
4. Considerar particionamiento de datos
5. Usar almacenamiento SSD

### **Configuraciones Recomendadas**
- **Umbral de base grande**: 10,000 documentos
- **Batch incremental**: 2,000 documentos
- **Checkpoint cada**: 5,000 documentos
- **L√≠mite de memoria**: 2,048 MB

## Manejo de Errores Mejorado

### **Detecci√≥n de Falta de Informaci√≥n**
- El sistema detecta cuando no hay informaci√≥n relevante
- Proporciona mensajes claros al usuario
- Evita respuestas falsas o inventadas

### **Recuperaci√≥n de Errores**
- Errores de batch: Reducci√≥n autom√°tica del tama√±o
- Errores de memoria: Limpieza autom√°tica y pausa
- Errores de proceso: Recuperaci√≥n desde checkpoint

## Ejemplos de Uso

### **Consulta Simple**
```python
# Consulta b√°sica
result = ask_rag("¬øQu√© es la inteligencia artificial?")
```

### **Consulta con Filtros**
```python
# Consulta filtrada por tipo de archivo
filter_metadata = {"file_type": ".pdf"}
result = ask_rag_filtered("Explica machine learning", filter_metadata)
```

### **Optimizaci√≥n Autom√°tica**
```python
# El sistema detecta autom√°ticamente el tama√±o y usa el m√©todo apropiado
result = optimize_vector_store()
```

### **Estad√≠sticas Avanzadas**
```python
# Obtener informaci√≥n completa de escalabilidad
stats = get_vector_store_stats_advanced()
print(f"Es base grande: {stats['is_large_database']}")
print(f"Tiempo estimado: {stats['estimated_optimization_time']}")
```

## Notas Importantes

1. **Detecci√≥n Autom√°tica**: Las funciones detectan autom√°ticamente si es necesario usar optimizaci√≥n incremental
2. **Monitoreo de Memoria**: Requiere `psutil` instalado para funcionar completamente
3. **Checkpoints**: Se guardan autom√°ticamente en `./temp_reindex/`
4. **Recuperaci√≥n**: Los errores en bases grandes son recuperables desde el √∫ltimo checkpoint
5. **Rendimiento**: Las estimaciones son aproximadas y pueden variar seg√∫n el hardware

## Troubleshooting

### **Error de Memoria**
- El sistema reduce autom√°ticamente el tama√±o de batch
- Limpia memoria y contin√∫a el proceso
- Considerar aumentar RAM si es frecuente

### **Error de Batch**
- Reducci√≥n autom√°tica del tama√±o de batch
- Procesamiento en sub-batches m√°s peque√±os
- Logs detallados para debugging

### **Error de Checkpoint**
- Verificar espacio en disco
- Limpiar directorio temporal si es necesario
- Reanudar desde el √∫ltimo checkpoint v√°lido 