"""
Herramientas de Utilidad para MCP
===============================

Este mÃ³dulo contiene herramientas de utilidad y mantenimiento.
Migradas desde rag_server.py para una arquitectura modular.

NOTA: Estas funciones estÃ¡n diseÃ±adas para ser decoradas con @mcp.tool() en el servidor principal.
"""

from rag_core import (
    get_document_statistics,
    get_cache_stats,
    clear_embedding_cache,
    optimize_vector_store,
    get_vector_store_stats,
    reindex_vector_store
)
from utils.logger import log

# Importar modelos estructurados
try:
    from models import MetadataModel
except ImportError as e:
    print(f"Advertencia: No se pudieron importar los modelos estructurados: {e}")
    MetadataModel = None

# Variables globales que deben estar disponibles en el servidor
rag_state = {}
initialize_rag_func = None

def set_rag_state(state):
    """Establece el estado RAG global."""
    global rag_state
    rag_state = state

def set_initialize_rag_func(func):
    """Establece la funciÃ³n de inicializaciÃ³n RAG."""
    global initialize_rag_func
    initialize_rag_func = func

def initialize_rag():
    """Inicializa el sistema RAG."""
    if initialize_rag_func:
        initialize_rag_func()
    elif "initialized" in rag_state:
        return
    # Esta funciÃ³n debe ser implementada en el servidor principal
    pass

def analyze_documents_with_models(vector_store) -> dict:
    """
    Analiza documentos usando modelos estructurados para obtener informaciÃ³n mÃ¡s detallada.
    
    Args:
        vector_store: La base de datos vectorial
        
    Returns:
        Diccionario con anÃ¡lisis detallado usando modelos
    """
    if MetadataModel is None:
        return {"error": "MetadataModel no disponible"}
    
    try:
        # Obtener todos los documentos
        all_docs = vector_store.get()
        
        if not all_docs or not all_docs['documents']:
            return {"total_documents": 0, "message": "Base de datos vacÃ­a"}
        
        documents = all_docs['documents']
        metadatas = all_docs.get('metadatas', [])
        
        # Convertir a modelos estructurados
        metadata_models = []
        for metadata in metadatas:
            if metadata:
                try:
                    metadata_model = MetadataModel.from_dict(metadata)
                    metadata_models.append(metadata_model)
                except Exception as e:
                    log(f"MCP Server Warning: Error convirtiendo metadatos a modelo: {e}")
        
        # AnÃ¡lisis usando modelos estructurados
        analysis = {
            "total_documents": len(documents),
            "structured_models": len(metadata_models),
            "file_types": {},
            "processing_methods": {},
            "chunking_methods": {},
            "content_quality": {
                "rich_content": 0,
                "standard_content": 0,
                "poor_content": 0
            },
            "structural_analysis": {
                "documents_with_tables": 0,
                "documents_with_titles": 0,
                "documents_with_lists": 0,
                "avg_tables_per_doc": 0,
                "avg_titles_per_doc": 0,
                "avg_lists_per_doc": 0,
                "avg_chunk_size": 0
            },
            "processing_quality": {
                "unstructured_enhanced": 0,
                "manual_input": 0,
                "markitdown": 0,
                "other": 0
            }
        }
        
        total_tables = 0
        total_titles = 0
        total_lists = 0
        total_chunk_sizes = 0
        
        for model in metadata_models:
            # Tipos de archivo
            file_type = model.file_type or "unknown"
            analysis["file_types"][file_type] = analysis["file_types"].get(file_type, 0) + 1
            
            # MÃ©todos de procesamiento
            processing_method = model.processing_method or "unknown"
            analysis["processing_methods"][processing_method] = analysis["processing_methods"].get(processing_method, 0) + 1
            
            # MÃ©todos de chunking
            chunking_method = model.chunking_method or "unknown"
            analysis["chunking_methods"][chunking_method] = analysis["chunking_methods"].get(chunking_method, 0) + 1
            
            # Calidad del contenido
            if model.is_rich_content():
                analysis["content_quality"]["rich_content"] += 1
            elif model.total_elements > 1:
                analysis["content_quality"]["standard_content"] += 1
            else:
                analysis["content_quality"]["poor_content"] += 1
            
            # AnÃ¡lisis estructural
            if model.tables_count > 0:
                analysis["structural_analysis"]["documents_with_tables"] += 1
                total_tables += model.tables_count
            
            if model.titles_count > 0:
                analysis["structural_analysis"]["documents_with_titles"] += 1
                total_titles += model.titles_count
            
            if model.lists_count > 0:
                analysis["structural_analysis"]["documents_with_lists"] += 1
                total_lists += model.lists_count
            
            # TamaÃ±o de chunks
            if model.avg_chunk_size > 0:
                total_chunk_sizes += model.avg_chunk_size
            
            # Calidad de procesamiento
            if processing_method == "unstructured_enhanced":
                analysis["processing_quality"]["unstructured_enhanced"] += 1
            elif processing_method == "manual_input":
                analysis["processing_quality"]["manual_input"] += 1
            elif processing_method == "markitdown":
                analysis["processing_quality"]["markitdown"] += 1
            else:
                analysis["processing_quality"]["other"] += 1
        
        # Calcular promedios
        if len(metadata_models) > 0:
            analysis["structural_analysis"]["avg_tables_per_doc"] = total_tables / len(metadata_models)
            analysis["structural_analysis"]["avg_titles_per_doc"] = total_titles / len(metadata_models)
            analysis["structural_analysis"]["avg_lists_per_doc"] = total_lists / len(metadata_models)
            analysis["structural_analysis"]["avg_chunk_size"] = total_chunk_sizes / len(metadata_models)
        
        return analysis
        
    except Exception as e:
        log(f"MCP Server Error: Error en anÃ¡lisis con modelos: {e}")
        return {"error": str(e)}

def get_knowledge_base_stats() -> str:
    """
    Gets comprehensive statistics about the knowledge base, including document types, processing methods, and structural information.
    Use this to understand what information is available in your knowledge base and how it was processed.
    
    Examples of when to use:
    - Checking how many documents are in the knowledge base
    - Understanding the distribution of file types
    - Seeing which processing methods were used
    - Analyzing the structural complexity of stored documents
    
    This helps you make informed decisions about what to search for and how to filter your queries.

    Returns:
        Detailed statistics about the knowledge base contents.
    """
    log(f"MCP Server: Obteniendo estadÃ­sticas de la base de conocimientos...")
    initialize_rag()
    
    try:
        # Obtener estadÃ­sticas bÃ¡sicas
        basic_stats = get_document_statistics(rag_state["vector_store"])
        
        if "error" in basic_stats:
            return f"âŒ **Error obteniendo estadÃ­sticas:** {basic_stats['error']}"
        
        if basic_stats.get("total_documents", 0) == 0:
            return "ğŸ“Š **Base de conocimientos vacÃ­a**\n\nNo hay documentos almacenados en la base de conocimientos."
        
        # Obtener anÃ¡lisis con modelos estructurados
        model_analysis = analyze_documents_with_models(rag_state["vector_store"])
        
        # Construir respuesta detallada
        response = f"ğŸ“Š **EstadÃ­sticas de la Base de Conocimientos**\n\n"
        response += f"ğŸ“š **Total de documentos:** {basic_stats['total_documents']}\n"
        
        # InformaciÃ³n sobre modelos estructurados si estÃ¡ disponible
        if "error" not in model_analysis and model_analysis.get("structured_models", 0) > 0:
            response += f"ğŸ§  **Documentos con modelos estructurados:** {model_analysis['structured_models']}\n"
            response += f"ğŸ“ˆ **AnÃ¡lisis avanzado disponible:** âœ…\n"
        else:
            response += f"ğŸ“ˆ **AnÃ¡lisis avanzado disponible:** âŒ (usando anÃ¡lisis bÃ¡sico)\n"
        
        response += "\n"
        
        # Tipos de archivo
        if basic_stats["file_types"]:
            response += "ğŸ“„ **Tipos de archivo:**\n"
            for file_type, count in sorted(basic_stats["file_types"].items(), key=lambda x: x[1], reverse=True):
                percentage = (count / basic_stats["total_documents"]) * 100
                response += f"   â€¢ {file_type.upper()}: {count} ({percentage:.1f}%)\n"
            response += "\n"
        
        # MÃ©todos de procesamiento
        if basic_stats["processing_methods"]:
            response += "ğŸ”§ **MÃ©todos de procesamiento:**\n"
            for method, count in sorted(basic_stats["processing_methods"].items(), key=lambda x: x[1], reverse=True):
                percentage = (count / basic_stats["total_documents"]) * 100
                method_display = method.replace('_', ' ').title()
                response += f"   â€¢ {method_display}: {count} ({percentage:.1f}%)\n"
            response += "\n"
        
        # MÃ©todos de chunking (solo si hay anÃ¡lisis con modelos)
        if "error" not in model_analysis and model_analysis.get("chunking_methods"):
            response += "ğŸ§© **MÃ©todos de chunking:**\n"
            for method, count in sorted(model_analysis["chunking_methods"].items(), key=lambda x: x[1], reverse=True):
                percentage = (count / model_analysis["structured_models"]) * 100
                method_display = method.replace('_', ' ').title()
                response += f"   â€¢ {method_display}: {count} ({percentage:.1f}%)\n"
            response += "\n"
        
        # Calidad del contenido (solo si hay anÃ¡lisis con modelos)
        if "error" not in model_analysis and model_analysis.get("content_quality"):
            response += "ğŸ“Š **Calidad del contenido:**\n"
            quality = model_analysis["content_quality"]
            total_analyzed = quality["rich_content"] + quality["standard_content"] + quality["poor_content"]
            
            if total_analyzed > 0:
                rich_pct = (quality["rich_content"] / total_analyzed) * 100
                standard_pct = (quality["standard_content"] / total_analyzed) * 100
                poor_pct = (quality["poor_content"] / total_analyzed) * 100
                
                response += f"   â€¢ ğŸŸ¢ Contenido rico en estructura: {quality['rich_content']} ({rich_pct:.1f}%)\n"
                response += f"   â€¢ ğŸŸ¡ Contenido estÃ¡ndar: {quality['standard_content']} ({standard_pct:.1f}%)\n"
                response += f"   â€¢ ğŸ”´ Contenido bÃ¡sico: {quality['poor_content']} ({poor_pct:.1f}%)\n"
            response += "\n"
        
        # EstadÃ­sticas estructurales
        structural = basic_stats["structural_stats"]
        response += "ğŸ—ï¸ **InformaciÃ³n estructural:**\n"
        response += f"   â€¢ Documentos con tablas: {structural['documents_with_tables']}\n"
        response += f"   â€¢ Documentos con tÃ­tulos: {structural['documents_with_titles']}\n"
        response += f"   â€¢ Documentos con listas: {structural['documents_with_lists']}\n"
        response += f"   â€¢ Promedio de tablas por documento: {structural['avg_tables_per_doc']:.1f}\n"
        response += f"   â€¢ Promedio de tÃ­tulos por documento: {structural['avg_titles_per_doc']:.1f}\n"
        response += f"   â€¢ Promedio de listas por documento: {structural['avg_lists_per_doc']:.1f}\n"
        
        # InformaciÃ³n adicional de modelos si estÃ¡ disponible
        if "error" not in model_analysis and model_analysis.get("structural_analysis"):
            model_structural = model_analysis["structural_analysis"]
            response += f"   â€¢ TamaÃ±o promedio de chunks: {model_structural['avg_chunk_size']:.0f} caracteres\n"
        
        response += "\n"
        
        # Sugerencias de bÃºsqueda mejoradas
        response += "ğŸ’¡ **Sugerencias de bÃºsqueda:**\n"
        if structural['documents_with_tables'] > 0:
            response += f"   â€¢ Usa `ask_rag_filtered` con `min_tables=1` para buscar informaciÃ³n en documentos con tablas\n"
        if structural['documents_with_titles'] > 5:
            response += f"   â€¢ Usa `ask_rag_filtered` con `min_titles=5` para buscar en documentos bien estructurados\n"
        if ".pdf" in basic_stats["file_types"]:
            response += f"   â€¢ Usa `ask_rag_filtered` con `file_type=\".pdf\"` para buscar solo en documentos PDF\n"
        
        # Sugerencias adicionales basadas en anÃ¡lisis de modelos
        if "error" not in model_analysis:
            if model_analysis["content_quality"]["rich_content"] > 0:
                response += f"   â€¢ Tienes {model_analysis['content_quality']['rich_content']} documentos con estructura rica - aprovecha el chunking semÃ¡ntico\n"
            if model_analysis["processing_quality"]["unstructured_enhanced"] > 0:
                response += f"   â€¢ {model_analysis['processing_quality']['unstructured_enhanced']} documentos procesados con Unstructured mejorado\n"
        
        log(f"MCP Server: EstadÃ­sticas obtenidas exitosamente")
        return response
        
    except Exception as e:
        log(f"MCP Server: Error obteniendo estadÃ­sticas: {e}")
        return f"âŒ **Error obteniendo estadÃ­sticas:** {e}"

def get_embedding_cache_stats() -> str:
    """
    Gets detailed statistics about the embedding cache performance.
    Use this to monitor cache efficiency and understand how the system is performing.
    
    Examples of when to use:
    - Checking cache hit rates to see if the system is working efficiently
    - Monitoring memory usage of the cache
    - Understanding how often embeddings are being reused
    - Debugging performance issues
    
    This helps you optimize the system and understand its behavior.

    Returns:
        Detailed statistics about the embedding cache performance.
    """
    log(f"MCP Server: Obteniendo estadÃ­sticas del cache de embeddings...")
    
    try:
        stats = get_cache_stats()
        
        if not stats:
            return "ğŸ“Š **Cache de embeddings no disponible**\n\nEl cache de embeddings no estÃ¡ inicializado."
        
        # Construir respuesta detallada
        response = f"ğŸ“Š **EstadÃ­sticas del Cache de Embeddings**\n\n"
        
        # MÃ©tricas principales
        response += f"ğŸ”„ **Actividad del cache:**\n"
        response += f"   â€¢ Total de solicitudes: {stats['total_requests']}\n"
        response += f"   â€¢ Hits en memoria: {stats['memory_hits']}\n"
        response += f"   â€¢ Hits en disco: {stats['disk_hits']}\n"
        response += f"   â€¢ Misses (no encontrados): {stats['misses']}\n\n"
        
        # Tasas de Ã©xito
        response += f"ğŸ“ˆ **Tasas de Ã©xito:**\n"
        response += f"   â€¢ Tasa de hits en memoria: {stats['memory_hit_rate']}\n"
        response += f"   â€¢ Tasa de hits en disco: {stats['disk_hit_rate']}\n"
        response += f"   â€¢ Tasa de hits total: {stats['overall_hit_rate']}\n\n"
        
        # Uso de memoria
        response += f"ğŸ’¾ **Uso de memoria:**\n"
        response += f"   â€¢ Embeddings en memoria: {stats['memory_cache_size']}\n"
        response += f"   â€¢ TamaÃ±o mÃ¡ximo: {stats['max_memory_size']}\n"
        response += f"   â€¢ Directorio de cache: {stats['cache_directory']}\n\n"
        
        # AnÃ¡lisis de rendimiento
        total_requests = stats['total_requests']
        if total_requests > 0:
            memory_hit_rate = float(stats['memory_hit_rate'].rstrip('%'))
            overall_hit_rate = float(stats['overall_hit_rate'].rstrip('%'))
            
            response += f"ğŸ¯ **AnÃ¡lisis de rendimiento:**\n"
            
            if overall_hit_rate > 70:
                response += f"   â€¢ âœ… Excelente rendimiento: {overall_hit_rate:.1f}% de hits\n"
            elif overall_hit_rate > 50:
                response += f"   â€¢ âš ï¸ Rendimiento moderado: {overall_hit_rate:.1f}% de hits\n"
            else:
                response += f"   â€¢ âŒ Rendimiento bajo: {overall_hit_rate:.1f}% de hits\n"
            
            if memory_hit_rate > 50:
                response += f"   â€¢ ğŸš€ Cache en memoria efectivo: {memory_hit_rate:.1f}% de hits en memoria\n"
            else:
                response += f"   â€¢ ğŸ’¾ Dependencia del disco: {memory_hit_rate:.1f}% de hits en memoria\n"
            
            # Sugerencias de optimizaciÃ³n
            response += f"\nğŸ’¡ **Sugerencias de optimizaciÃ³n:**\n"
            if overall_hit_rate < 30:
                response += f"   â€¢ Considera procesar documentos similares juntos\n"
                response += f"   â€¢ Revisa si hay muchos textos Ãºnicos que no se repiten\n"
            
            if memory_hit_rate < 30 and total_requests > 100:
                response += f"   â€¢ Considera aumentar el tamaÃ±o del cache en memoria\n"
                response += f"   â€¢ Los hits en disco son mÃ¡s lentos que en memoria\n"
            
            if stats['memory_cache_size'] >= stats['max_memory_size'] * 0.9:
                response += f"   â€¢ El cache en memoria estÃ¡ casi lleno\n"
                response += f"   â€¢ Considera aumentar max_memory_size si tienes RAM disponible\n"
        
        log(f"MCP Server: EstadÃ­sticas del cache obtenidas exitosamente")
        return response
        
    except Exception as e:
        log(f"MCP Server: Error obteniendo estadÃ­sticas del cache: {e}")
        return f"âŒ **Error obteniendo estadÃ­sticas del cache:** {e}"

def clear_embedding_cache_tool() -> str:
    """
    Clears the embedding cache to free up memory and disk space.
    Use this when you want to reset the cache or free up resources.
    
    Examples of when to use:
    - Freeing up memory when the system is running low on RAM
    - Resetting the cache after making changes to the embedding model
    - Clearing old cached embeddings that are no longer needed
    - Troubleshooting cache-related issues
    
    Warning: This will remove all cached embeddings and they will need to be recalculated.

    Returns:
        Confirmation message about the cache clearing operation.
    """
    log(f"MCP Server: Limpiando cache de embeddings...")
    
    try:
        clear_embedding_cache()
        
        response = "ğŸ§¹ **Cache de embeddings limpiado exitosamente**\n\n"
        response += "âœ… Se han eliminado todos los embeddings almacenados en cache.\n"
        response += "ğŸ“ Los prÃ³ximos embeddings se calcularÃ¡n desde cero.\n"
        response += "ğŸ’¾ Se ha liberado memoria y espacio en disco.\n\n"
        response += "âš ï¸ **Nota:** Los embeddings se recalcularÃ¡n automÃ¡ticamente cuando sea necesario."
        
        log(f"MCP Server: Cache de embeddings limpiado exitosamente")
        return response
        
    except Exception as e:
        log(f"MCP Server: Error limpiando cache: {e}")
        return f"âŒ **Error limpiando cache:** {e}"

def optimize_vector_database() -> str:
    """
    Optimiza la base de datos vectorial para mejorar el rendimiento de bÃºsquedas.
    Esta herramienta reorganiza los Ã­ndices internos para bÃºsquedas mÃ¡s rÃ¡pidas.
    
    Use esta herramienta cuando:
    - Las bÃºsquedas son lentas
    - Se han aÃ±adido muchos documentos nuevos
    - Quieres mejorar el rendimiento general del sistema
    
    Returns:
        InformaciÃ³n sobre el proceso de optimizaciÃ³n
    """
    log("MCP Server: Optimizando base de datos vectorial...")
    
    try:
        result = optimize_vector_store()
        
        if result["status"] == "success":
            response = f"âœ… **Base de datos vectorial optimizada exitosamente**\n\n"
            response += f"ğŸ“Š **EstadÃ­sticas antes de la optimizaciÃ³n:**\n"
            stats_before = result.get("stats_before", {})
            response += f"   â€¢ Documentos totales: {stats_before.get('total_documents', 'N/A')}\n"
            
            response += f"\nğŸ“Š **EstadÃ­sticas despuÃ©s de la optimizaciÃ³n:**\n"
            stats_after = result.get("stats_after", {})
            response += f"   â€¢ Documentos totales: {stats_after.get('total_documents', 'N/A')}\n"
            
            response += f"\nğŸš€ **Beneficios:**\n"
            response += f"   â€¢ BÃºsquedas mÃ¡s rÃ¡pidas\n"
            response += f"   â€¢ Mejor precisiÃ³n en resultados\n"
            response += f"   â€¢ Ãndices optimizados\n"
            
        else:
            response = f"âŒ **Error optimizando base de datos:** {result.get('message', 'Error desconocido')}"
            
        return response
        
    except Exception as e:
        log(f"MCP Server Error: Error en optimizaciÃ³n: {e}")
        return f"âŒ **Error optimizando base de datos vectorial:** {str(e)}"

def get_vector_database_stats() -> str:
    """
    Obtiene estadÃ­sticas detalladas de la base de datos vectorial.
    Incluye informaciÃ³n sobre documentos, tipos de archivo y configuraciÃ³n.
    
    Use esta herramienta para:
    - Verificar el estado de la base de datos
    - Analizar la distribuciÃ³n de documentos
    - Diagnosticar problemas de rendimiento
    - Planificar optimizaciones
    
    Returns:
        EstadÃ­sticas detalladas de la base de datos vectorial
    """
    log("MCP Server: Obteniendo estadÃ­sticas de base de datos vectorial...")
    
    try:
        stats = get_vector_store_stats()
        
        if "error" in stats:
            return f"âŒ **Error obteniendo estadÃ­sticas:** {stats['error']}"
        
        response = f"ğŸ“Š **EstadÃ­sticas de la Base de Datos Vectorial**\n\n"
        
        response += f"ğŸ“š **InformaciÃ³n General:**\n"
        response += f"   â€¢ Total de documentos: {stats.get('total_documents', 0)}\n"
        response += f"   â€¢ Nombre de colecciÃ³n: {stats.get('collection_name', 'N/A')}\n"
        response += f"   â€¢ DimensiÃ³n de embeddings: {stats.get('embedding_dimension', 'N/A')}\n"
        
        # Tipos de archivo
        file_types = stats.get('file_types', {})
        if file_types:
            response += f"\nğŸ“„ **DistribuciÃ³n por tipo de archivo:**\n"
            for file_type, count in file_types.items():
                response += f"   â€¢ {file_type}: {count} documentos\n"
        
        # MÃ©todos de procesamiento
        processing_methods = stats.get('processing_methods', {})
        if processing_methods:
            response += f"\nğŸ”§ **MÃ©todos de procesamiento:**\n"
            for method, count in processing_methods.items():
                response += f"   â€¢ {method}: {count} documentos\n"
        
        # InformaciÃ³n de rendimiento
        performance = stats.get('performance', {})
        if performance:
            response += f"\nâš¡ **InformaciÃ³n de rendimiento:**\n"
            response += f"   â€¢ Tiempo de indexaciÃ³n: {performance.get('indexing_time', 'N/A')}\n"
            response += f"   â€¢ TamaÃ±o de Ã­ndice: {performance.get('index_size', 'N/A')}\n"
        
        log(f"MCP Server: EstadÃ­sticas de base de datos vectorial obtenidas exitosamente")
        return response
        
    except Exception as e:
        log(f"MCP Server: Error obteniendo estadÃ­sticas de base de datos vectorial: {e}")
        return f"âŒ **Error obteniendo estadÃ­sticas de base de datos vectorial:** {str(e)}"

def reindex_vector_database(profile: str = 'auto') -> str:
    """
    Reindexa la base de datos vectorial con una configuraciÃ³n optimizada.
    Esta herramienta recrea los Ã­ndices con parÃ¡metros optimizados para el tamaÃ±o actual.
    
    Args:
        profile: Perfil de configuraciÃ³n ('small', 'medium', 'large', 'auto')
                 'auto' detecta automÃ¡ticamente el perfil Ã³ptimo
    
    Use esta herramienta cuando:
    - Cambias el perfil de configuraciÃ³n
    - Las bÃºsquedas son muy lentas
    - Quieres optimizar para un tamaÃ±o especÃ­fico de base de datos
    - Hay problemas de rendimiento persistentes
    
    âš ï¸ **Nota:** Este proceso puede tomar tiempo dependiendo del tamaÃ±o de la base de datos.
    
    Returns:
        InformaciÃ³n sobre el proceso de reindexado
    """
    log(f"MCP Server: Reindexando base de datos vectorial con perfil '{profile}'...")
    
    try:
        result = reindex_vector_store(profile=profile)
        
        if result["status"] == "success":
            response = f"âœ… **Base de datos vectorial reindexada exitosamente**\n\n"
            response += f"ğŸ“Š **Perfil aplicado:** {result.get('profile', 'N/A')}\n"
            response += f"ğŸ“Š **Documentos procesados:** {result.get('documents_processed', 'N/A')}\n"
            response += f"â±ï¸ **Tiempo de reindexado:** {result.get('reindexing_time', 'N/A')}\n"
            
            response += f"\nğŸš€ **Beneficios del reindexado:**\n"
            response += f"   â€¢ Ãndices optimizados para el tamaÃ±o actual\n"
            response += f"   â€¢ BÃºsquedas mÃ¡s rÃ¡pidas y precisas\n"
            response += f"   â€¢ Mejor distribuciÃ³n de datos\n"
            
        else:
            response = f"âŒ **Error reindexando base de datos:** {result.get('message', 'Error desconocido')}"
            
        return response
        
    except Exception as e:
        log(f"MCP Server: Error reindexando base de datos vectorial: {e}")
        return f"âŒ **Error reindexando base de datos vectorial:** {str(e)}" 